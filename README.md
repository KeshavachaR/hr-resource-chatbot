---
title: HR Resource Chatbot
emoji: ğŸ§‘â€ğŸ’¼
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# ğŸ§‘â€ğŸ’¼ HR Resource Chatbot

An AI-powered chatbot designed to query structured HR datasets efficiently using semantic search and natural language generation. Built with a modular architecture featuring a FastAPI backend, Streamlit frontend, and local LLM support (Ollama + Llama3).

---

## ğŸš€ Features

- ğŸ” **Hybrid Retrieval**: FAISS-based semantic search with optional lexical fallback.
- ğŸ¤– **Local LLM Integration**: Uses Llama3 (via Ollama) for context-aware, natural language responses.
- âš¡ **FastAPI Backend**: Clean REST API for chat and health endpoints.
- ğŸ¨ **Streamlit Frontend**: Interactive and user-friendly chat interface.
- ğŸ› ï¸ **Resilient Design**: Graceful fallback to semantic-only mode if LLM is unavailable.
- ğŸ–¥ï¸ **Flexible Deployment**: Run locally, in Docker, or on Hugging Face Spaces (GPU/CPU).

---

## ğŸ§± Architecture

**Core Components:**

- **Data Layer** â†’ `employees.json` structured HR dataset.
- **Retriever** â†’ SentenceTransformers + FAISS for embedding-based semantic search.
- **Generator** â†’ Local LLM (Llama3 via Ollama) for answer synthesis.
- **API Layer** â†’ FastAPI app with `/chat` and `/health` endpoints.
- **UI Layer** â†’ Streamlit-based frontend for user interaction.

**Deployment Modes:**

| Mode        | Description                                  |
|-------------|----------------------------------------------|
| ğŸŸ¢ GPU      | Full chatbot with Ollama + Llama3            |
| ğŸ”µ CPU      | Fallback chatbot (semantic search only)      |
| âšª ZeroGPU  | Limited CPU-only demo (LLM not available)     |

---

## ğŸ› ï¸ Setup & Installation

### 1. Clone the Repository
git clone https://huggingface.co/spaces/keshav1236/hr-resource-chatbot

cd hr-resource-chatbot

### 2.Install Dependencies
pip install -r requirements.txt

### 3.Run Backend(FastAPI)
uvicorn app.main:app --reload --port 8000

### 4.Run Frontend
streamlit run frontend/streamlit_app.py

ğŸ§ª API Documentation
âœ… GET /health

Health check endpoint.

Response:

{
  "status": "ok",
  "mode": "semantic",
  "semantic_available": true
}

ğŸ’¬ POST /chat

Submit an HR query.

Request:

{
  "query": "Find Python developers in Bengaluru"
}


Response:

{
  "answer": "Found 2 Python developers with 3+ years experience in Bengaluru."
}

ğŸ“ Example HR Dataset Structure (employees.json)
[
  {
    "id": 1,
    "name": "Alice Johnson",
    "title": "Senior Python Developer",
    "skills": [
      "Python",
      "Django",
      "AWS",
      "Docker"
    ],
    "experience_years": 6,
    "projects": [
      "E-commerce Platform",
      "Healthcare Dashboard",
      "Data Pipeline on AWS"
    ],
    "availability": "available",
    "domains": [
      "ecommerce",
      "healthcare"
    ],
    "location": "Bengaluru"
  },
  {
    "id": 2,
    "name": "Michael Rodriguez",
    "title": "ML Engineer",
    "skills": [
      "Machine Learning",
      "scikit-learn",
      "pandas",
      "AWS"
    ],
    "experience_years": 4,
    "projects": [
      "Patient Risk Prediction System",
      "Fraud Detection"
    ],
    "availability": "available",
    "domains": [
      "healthcare",
      "fintech"
    ],
    "location": "Hyderabad"
  }
]


ğŸ“Œ Technical Stack

LLM Serving â†’ Ollama
 with LLaMA3

Semantic Search â†’ FAISS + SentenceTransformers

Backend API â†’ FastAPI

Frontend UI â†’ Streamlit

Containerization â†’ Docker (GPU + CPU Dockerfiles)

Deployment â†’ Hugging Face Spaces (ZeroGPU, CPU, or GPU modes)

ğŸ’¡ Future Enhancements

ğŸ” Add authentication for secure query access.

ğŸ“‚ Support uploading custom HR datasets.

ğŸ“Š Add filters and visual HR analytics to the UI.

âš™ï¸ Optimize Ollama LLM serving for faster responses.

ğŸ§  Example Queries

"List Java developers with 5+ years of experience."

"Who are the data scientists in New York?"

"Find remote HR managers in Bengaluru."

ğŸ“¦ Docker Support

The Hugging Face Space uses the provided Dockerfile (for GPU).
For CPU-only environments, use Dockerfile.cpu in Settings â†’ Dockerfile path.

ğŸ¤ Contributing

PRs and feedback are welcome! Please open an issue for feature requests or bugs.
